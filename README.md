# JSON Viewer - Агрегатор данных из Telegram

Проект с Летней Школы СПбГУ 2025. Сбор, обработка и просмотр данных из Telegram-каналов с фокусом на AI/ML контент.

## Возможности

- **Скрапинг Telegram-каналов** - автоматический сбор сообщений из настроенных каналов
- **Фильтрация по ключевым словам** - поиск по AI/ML тематике
- **Дедупликация контента** - удаление дублирующихся постов
- **Суммаризация** - автоматическое создание кратких описаний постов
- **Веб-интерфейс** - удобный просмотр и навигация по данным
- **Загрузка файлов** - поддержка загрузки и выбора JSON файлов
- **Фильтрация и сортировка** - поиск, фильтры по релевантности и ключевым словам

## Установка

### Требования
- Python 3.10
- pip

```bash
pip install -r requirements.txt
```

**Настройте переменные окружения:**
Создайте файл `.env` в корневой директории:
```env
# Telegram API (получите на https://my.telegram.org)
API_ID=your_api_id
API_HASH=your_api_hash

# GigaChat API (для суммаризации)
GIGACHAT_CREDENTIALS=your_gigachat_credentials
```

### Запуск
```bash
python server.py --json-file path/to/your/file.json
```

Сервер будет доступен по адресу: http://localhost:8000

## Использование

### Основные функции

1. **Обновление данных** - кнопка "Обновить данные" запускает полный пайплайн:
   - Скрапинг Telegram-каналов
   - Фильтрация по ключевым словам
   - Дедупликация
   - Суммаризация

2. **Загрузка файлов** - кнопка "Загрузить JSON" для загрузки новых файлов

3. **Выбор файлов** - кнопка "Выбрать файл" для выбора из существующих файлов

4. **Фильтрация и поиск** - поиск по тексту, фильтры по релевантности и ключевым словам

### CLI инструменты

#### Скрапинг данных
```bash
python scraping.py --limit 100 --output output/data.json
```

Параметры:
- `--limit` - количество сообщений для сбора с каждого канала
- `--offset-date` - дата начала сбора (YYYY-MM-DD)
- `--output` - путь к выходному файлу
- `--channels` - список каналов для скрапинга

#### Обработка данных
```bash
python pipeline.py --limit 150 --only-most-keywords
```

Параметры:
- `--limit` - количество сообщений для обработки
- `--keywords` - ключевые слова для фильтрации
- `--dedup-threshold` - порог дедупликации (0.0-1.0)
- `--no-dedup` - пропустить дедупликацию
- `--no-scraping` - пропустить скрапинг
- `--only-most-keywords` - только суммаризация топ-постов
- `--output` - путь к выходному файлу

## Структура проекта

```
json-viewer/
├── server.py              # Основной веб-сервер
├── scraping.py            # Скрипт скрапинга Telegram
├── pipeline.py            # Пайплайн обработки данных
├── requirements.txt       # Зависимости Python
├── .env                   # Переменные окружения
├── templates/             # HTML шаблоны
│   ├── index.html        # Главная страница
│   └── item.html         # Страница отдельного поста
├── static/               # Статические файлы
│   └── style.css         # Стили CSS
├── output/               # Выходные файлы скрапинга
├── pipeline_output/      # Обработанные JSON файлы
└── uploads/              # Загруженные пользователем файлы
```

## Настройка каналов

Для изменения списка каналов отредактируйте переменную `channels` в файле `scraping.py`:

```python
channels = [
    'ai_newz',
    'gonzo_ML',
    ...
    # добавьте свои каналы
]
```

## Лицензия

MIT License 